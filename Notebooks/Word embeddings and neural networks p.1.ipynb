{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks # 1: Classification with a 1-Layer Network\n",
    "In this notebook you will find a first example on the use of a simple neural network for the classification of texts. We present here the basic concepts related to neural networks and some basic information on the PyTorch library.\n",
    "\n",
    "In this example, an architecture comprising a single layer of neurons (perceptrons) is used. A perceptron is a neuron that:\n",
    "* takes as input a vector of numeric value\n",
    "* multiply each of the values by a weight\n",
    "* applies an activation function to produce an output result (optional).\n",
    "\n",
    "See the description on Wikipedia for more details.\n",
    "\n",
    "This is equivalent to a neural network without a hidden layer. It is also equivalent to a logistic regression if the activation function is or a softmax (multiclass classification).\n",
    "\n",
    "The dependencies needed to run these examples are:\n",
    "* gensim\n",
    "* torch==1.6\n",
    "* torchvision\n",
    "* wget\n",
    "* sklearn\n",
    "* numpy\n",
    "* matplotlib\n",
    "* poutyne\n",
    "* pandas\n",
    "* spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creation of the dataset\n",
    "As for the example of text classification seen during the 3rd week of this course, we will use the 20newsgroup corpus to conduct our tests. This corpus is available through scikit-learn.\n",
    "\n",
    "We create 2 sets of examples:\n",
    "\n",
    "* train: texts used for network training\n",
    "* valid: the texts used to evaluate the performance of the network at each iteration of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les classes sont: ['rec.autos', 'rec.sport.hockey', 'sci.med', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# On utilise le corpus 20Newsgroups et on limite les exemples d'entraînement à 4 classes\n",
    "wanted_categories = ['rec.sport.hockey', 'sci.space', 'rec.autos', 'sci.med']\n",
    "training_corpus = fetch_20newsgroups(subset='train', categories=wanted_categories, shuffle=True)\n",
    "validation_corpus = fetch_20newsgroups(subset='test', categories=wanted_categories, shuffle=True)\n",
    "\n",
    "target_categories = training_corpus.target_names\n",
    "\n",
    "# On créer un sac de mots (Bag of Words - BOW) avec l'ensemble d'entrainement \n",
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "X_train = vectorizer.fit_transform(training_corpus.data)\n",
    "y_train = training_corpus.target\n",
    "\n",
    "# On réutilise le CountVectorizer pour transformer l'ensemble de validation en sac de mots\n",
    "X_valid = vectorizer.transform(validation_corpus.data)\n",
    "y_valid = validation_corpus.target \n",
    "\n",
    "print(\"Les classes sont:\", target_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a 1-layer neural network architecture\n",
    "The architecture for this example is a single-layer network that:\n",
    "\n",
    "* takes as input vectors generated by the CountVectorizer. The dimension of these vectors is 37,000 (the number of different words in the corpus)\n",
    "* has 4 neurons at the output that correspond to the classes of our texts (cars, hockey, med and space).\n",
    "\n",
    "In the PyTorch library, this corresponds to a linear layer (nn.Linear). In other words, we apply a linear transformation on the vectors of counts x as input by using the weights W of the network (z = Wx + b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=37000, out_features=4, bias=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "bow_size = X_train.shape[1]\n",
    "nb_classes = len(target_categories)\n",
    "\n",
    "perceptron = nn.Linear(bow_size, nb_classes)\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creation of a dataloader to iterate on the data in minibatch\n",
    "In this section, we define a utility function that allows you to group the examples into sets of fixed size (minibatches). See the section \"training a neural network\" in the course notes or in the first video clip on neural networks.\n",
    "\n",
    "The main ideas to remember are as follows:\n",
    "\n",
    "* When training a neural network, one can use at each iteration either 1 single example, a few examples or all the examples before updating the weights of the network.\n",
    "* For stochastic gradient descent (SGD) training, a few examples are used - a minibatch.\n",
    "* So a minibatch simply means that we present some examples to the network in order to update the weights of its links.\n",
    "* In the Deep learning libraries, the examples are represented in the form of tensors. A tensor is a matrix in several dimensions.\n",
    "* In our case, we have tensors in 2 dimensions:\n",
    " * a dimension which corresponds to the vectors of words (| V | = 37,000) and\n",
    " * another which corresponds to the number of examples presented to the neural network (batch_size = 16).\n",
    "* A DataLoader is a utility class in PyTorch that manages minibatches. So which allows you to take a set of examples and divide it into several groups of the same size (batch_size).\n",
    "* Last detail: we use here a sparse matrix (scipy.sparse import csr_matrix) because our document vectors contain a lot of 0s.\n",
    "\n",
    "This should give you the essentials to understand the rest. But it is not important to remember all the implementation details because you will not be evaluated on these aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import FloatTensor, LongTensor\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "class SparseMatrixDataset(Dataset):\n",
    "    def __init__(self, dataset_in_csr_matrix: csr_matrix, target: np.array):\n",
    "        self.dataset = dataset_in_csr_matrix\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return FloatTensor(self.dataset[index,:].todense()).squeeze(0), LongTensor([self.target[index]]).squeeze(0)\n",
    "        \n",
    "def get_dataloader(base_dataset, dataset_target, dataset_class):\n",
    "    return DataLoader(dataset_class(base_dataset, dataset_target), batch_size=16, shuffle=True)\n",
    "\n",
    "train_loader = get_dataloader(X_train, y_train, SparseMatrixDataset)\n",
    "valid_loader = get_dataloader(X_valid, y_valid, SparseMatrixDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a training loop\n",
    "In this step, we implement the network drive loop. As seen in the course, this loop consists of applying the following steps:\n",
    "\n",
    "* Present a set of examples (minibatch) to the neural network\n",
    "* Obtain the results for each of these examples (forward propagation)\n",
    "* Calculate the cumulative loss on these examples\n",
    "* Propagate errors backwards (backpropagation) in order to modify the network weights using gradient descent\n",
    "\n",
    "To simplify the whole thing, we use the Poutyne library which makes it possible to hide the complexity of the instructions necessary to train a neural network. All this is taken care of by the Experiment class which manages the learning (experiment.train) only from the description of the network (perceptron) and some parameters describing how to conduct the training:\n",
    "\n",
    "* we have a classification task\n",
    "* we want an optimization of the stochastic gradient descent type (SGD)\n",
    "* we reuse our dataset 30 times to train the network (epochs = 30)\n",
    "* the model is saved in the \"./model/perceptron\" directory as well as statistics on learning.\n",
    "* we use the data_loader created in the previous step to manage the examples during training (train_loader) and for the evaluation of the model (valid_loader)\n",
    "\n",
    "It takes about 1 minute to train the model.\n",
    "\n",
    "Poutyne was developed by one of our doctoral students (Frédérik Paradis) and is a good tool to add to your safe if you want to do work with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poutyne.framework import Experiment\n",
    "from poutyne import set_seeds\n",
    "from torch.optim import SGD\n",
    "\n",
    "set_seeds(42)\n",
    "experiment = Experiment('model/perceptron', perceptron, optimizer = \"SGD\", task=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mEpoch: \u001b[36m1/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.54s \u001b[35mloss:\u001b[94m 0.923344\u001b[35m acc:\u001b[94m 72.574549\u001b[35m fscore_micro:\u001b[94m 0.725745\u001b[35m val_loss:\u001b[94m 0.733501\u001b[35m val_acc:\u001b[94m 81.324921\u001b[35m val_fscore_micro:\u001b[94m 0.813249\u001b[0m\n",
      "Epoch 1: val_acc improved from -inf to 81.32492, saving file to model/perceptron\\checkpoint_epoch_1.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.71s \u001b[35mloss:\u001b[94m 0.493188\u001b[35m acc:\u001b[94m 91.852163\u001b[35m fscore_micro:\u001b[94m 0.918522\u001b[35m val_loss:\u001b[94m 0.584016\u001b[35m val_acc:\u001b[94m 87.066246\u001b[35m val_fscore_micro:\u001b[94m 0.870662\u001b[0m\n",
      "Epoch 2: val_acc improved from 81.32492 to 87.06625, saving file to model/perceptron\\checkpoint_epoch_2.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.93s \u001b[35mloss:\u001b[94m 0.382614\u001b[35m acc:\u001b[94m 94.960101\u001b[35m fscore_micro:\u001b[94m 0.949601\u001b[35m val_loss:\u001b[94m 0.530257\u001b[35m val_acc:\u001b[94m 87.949527\u001b[35m val_fscore_micro:\u001b[94m 0.879495\u001b[0m\n",
      "Epoch 3: val_acc improved from 87.06625 to 87.94953, saving file to model/perceptron\\checkpoint_epoch_3.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.81s \u001b[35mloss:\u001b[94m 0.327187\u001b[35m acc:\u001b[94m 95.548089\u001b[35m fscore_micro:\u001b[94m 0.955481\u001b[35m val_loss:\u001b[94m 0.482115\u001b[35m val_acc:\u001b[94m 89.337539\u001b[35m val_fscore_micro:\u001b[94m 0.893375\u001b[0m\n",
      "Epoch 4: val_acc improved from 87.94953 to 89.33754, saving file to model/perceptron\\checkpoint_epoch_4.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.18s \u001b[35mloss:\u001b[94m 0.282650\u001b[35m acc:\u001b[94m 96.472071\u001b[35m fscore_micro:\u001b[94m 0.964721\u001b[35m val_loss:\u001b[94m 0.460868\u001b[35m val_acc:\u001b[94m 89.022082\u001b[35m val_fscore_micro:\u001b[94m 0.890221\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m6/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.88s \u001b[35mloss:\u001b[94m 0.253192\u001b[35m acc:\u001b[94m 96.892062\u001b[35m fscore_micro:\u001b[94m 0.968921\u001b[35m val_loss:\u001b[94m 0.433433\u001b[35m val_acc:\u001b[94m 89.652997\u001b[35m val_fscore_micro:\u001b[94m 0.896530\u001b[0m\n",
      "Epoch 6: val_acc improved from 89.33754 to 89.65300, saving file to model/perceptron\\checkpoint_epoch_6.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m7/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.53s \u001b[35mloss:\u001b[94m 0.230972\u001b[35m acc:\u001b[94m 97.690046\u001b[35m fscore_micro:\u001b[94m 0.976900\u001b[35m val_loss:\u001b[94m 0.412914\u001b[35m val_acc:\u001b[94m 90.157729\u001b[35m val_fscore_micro:\u001b[94m 0.901577\u001b[0m\n",
      "Epoch 7: val_acc improved from 89.65300 to 90.15773, saving file to model/perceptron\\checkpoint_epoch_7.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m8/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.77s \u001b[35mloss:\u001b[94m 0.212284\u001b[35m acc:\u001b[94m 97.774045\u001b[35m fscore_micro:\u001b[94m 0.977740\u001b[35m val_loss:\u001b[94m 0.401749\u001b[35m val_acc:\u001b[94m 90.410095\u001b[35m val_fscore_micro:\u001b[94m 0.904101\u001b[0m\n",
      "Epoch 8: val_acc improved from 90.15773 to 90.41009, saving file to model/perceptron\\checkpoint_epoch_8.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m9/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.93s \u001b[35mloss:\u001b[94m 0.196603\u001b[35m acc:\u001b[94m 98.236035\u001b[35m fscore_micro:\u001b[94m 0.982360\u001b[35m val_loss:\u001b[94m 0.383416\u001b[35m val_acc:\u001b[94m 91.104101\u001b[35m val_fscore_micro:\u001b[94m 0.911041\u001b[0m\n",
      "Epoch 9: val_acc improved from 90.41009 to 91.10410, saving file to model/perceptron\\checkpoint_epoch_9.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m10/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.60s \u001b[35mloss:\u001b[94m 0.183340\u001b[35m acc:\u001b[94m 98.362033\u001b[35m fscore_micro:\u001b[94m 0.983620\u001b[35m val_loss:\u001b[94m 0.377459\u001b[35m val_acc:\u001b[94m 90.220820\u001b[35m val_fscore_micro:\u001b[94m 0.902208\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m11/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.64s \u001b[35mloss:\u001b[94m 0.172140\u001b[35m acc:\u001b[94m 98.656027\u001b[35m fscore_micro:\u001b[94m 0.986560\u001b[35m val_loss:\u001b[94m 0.362907\u001b[35m val_acc:\u001b[94m 91.230284\u001b[35m val_fscore_micro:\u001b[94m 0.912303\u001b[0m\n",
      "Epoch 11: val_acc improved from 91.10410 to 91.23028, saving file to model/perceptron\\checkpoint_epoch_11.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m12/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.70s \u001b[35mloss:\u001b[94m 0.162290\u001b[35m acc:\u001b[94m 98.698026\u001b[35m fscore_micro:\u001b[94m 0.986980\u001b[35m val_loss:\u001b[94m 0.357158\u001b[35m val_acc:\u001b[94m 91.230284\u001b[35m val_fscore_micro:\u001b[94m 0.912303\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m13/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.16s \u001b[35mloss:\u001b[94m 0.153499\u001b[35m acc:\u001b[94m 98.824024\u001b[35m fscore_micro:\u001b[94m 0.988240\u001b[35m val_loss:\u001b[94m 0.348392\u001b[35m val_acc:\u001b[94m 91.293375\u001b[35m val_fscore_micro:\u001b[94m 0.912934\u001b[0m\n",
      "Epoch 13: val_acc improved from 91.23028 to 91.29338, saving file to model/perceptron\\checkpoint_epoch_13.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m14/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.64s \u001b[35mloss:\u001b[94m 0.145489\u001b[35m acc:\u001b[94m 98.866023\u001b[35m fscore_micro:\u001b[94m 0.988660\u001b[35m val_loss:\u001b[94m 0.341092\u001b[35m val_acc:\u001b[94m 91.608833\u001b[35m val_fscore_micro:\u001b[94m 0.916088\u001b[0m\n",
      "Epoch 14: val_acc improved from 91.29338 to 91.60883, saving file to model/perceptron\\checkpoint_epoch_14.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m15/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.08s \u001b[35mloss:\u001b[94m 0.138792\u001b[35m acc:\u001b[94m 99.034019\u001b[35m fscore_micro:\u001b[94m 0.990340\u001b[35m val_loss:\u001b[94m 0.335905\u001b[35m val_acc:\u001b[94m 91.482650\u001b[35m val_fscore_micro:\u001b[94m 0.914827\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m16/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.61s \u001b[35mloss:\u001b[94m 0.132656\u001b[35m acc:\u001b[94m 99.160017\u001b[35m fscore_micro:\u001b[94m 0.991600\u001b[35m val_loss:\u001b[94m 0.328509\u001b[35m val_acc:\u001b[94m 91.735016\u001b[35m val_fscore_micro:\u001b[94m 0.917350\u001b[0m\n",
      "Epoch 16: val_acc improved from 91.60883 to 91.73502, saving file to model/perceptron\\checkpoint_epoch_16.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m17/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.53s \u001b[35mloss:\u001b[94m 0.126991\u001b[35m acc:\u001b[94m 99.202016\u001b[35m fscore_micro:\u001b[94m 0.992020\u001b[35m val_loss:\u001b[94m 0.323229\u001b[35m val_acc:\u001b[94m 91.735016\u001b[35m val_fscore_micro:\u001b[94m 0.917350\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m18/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.59s \u001b[35mloss:\u001b[94m 0.121677\u001b[35m acc:\u001b[94m 99.286014\u001b[35m fscore_micro:\u001b[94m 0.992860\u001b[35m val_loss:\u001b[94m 0.319950\u001b[35m val_acc:\u001b[94m 91.798107\u001b[35m val_fscore_micro:\u001b[94m 0.917981\u001b[0m\n",
      "Epoch 18: val_acc improved from 91.73502 to 91.79811, saving file to model/perceptron\\checkpoint_epoch_18.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m19/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.60s \u001b[35mloss:\u001b[94m 0.116908\u001b[35m acc:\u001b[94m 99.370013\u001b[35m fscore_micro:\u001b[94m 0.993700\u001b[35m val_loss:\u001b[94m 0.314811\u001b[35m val_acc:\u001b[94m 91.798107\u001b[35m val_fscore_micro:\u001b[94m 0.917981\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m20/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.27s \u001b[35mloss:\u001b[94m 0.112432\u001b[35m acc:\u001b[94m 99.370013\u001b[35m fscore_micro:\u001b[94m 0.993700\u001b[35m val_loss:\u001b[94m 0.311905\u001b[35m val_acc:\u001b[94m 91.861199\u001b[35m val_fscore_micro:\u001b[94m 0.918612\u001b[0m\n",
      "Epoch 20: val_acc improved from 91.79811 to 91.86120, saving file to model/perceptron\\checkpoint_epoch_20.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m21/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m5.35s \u001b[35mloss:\u001b[94m 0.108357\u001b[35m acc:\u001b[94m 99.412012\u001b[35m fscore_micro:\u001b[94m 0.994120\u001b[35m val_loss:\u001b[94m 0.308889\u001b[35m val_acc:\u001b[94m 91.861199\u001b[35m val_fscore_micro:\u001b[94m 0.918612\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m22/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.19s \u001b[35mloss:\u001b[94m 0.104596\u001b[35m acc:\u001b[94m 99.454011\u001b[35m fscore_micro:\u001b[94m 0.994540\u001b[35m val_loss:\u001b[94m 0.307617\u001b[35m val_acc:\u001b[94m 92.050473\u001b[35m val_fscore_micro:\u001b[94m 0.920505\u001b[0m\n",
      "Epoch 22: val_acc improved from 91.86120 to 92.05047, saving file to model/perceptron\\checkpoint_epoch_22.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m23/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m5.76s \u001b[35mloss:\u001b[94m 0.101126\u001b[35m acc:\u001b[94m 99.454011\u001b[35m fscore_micro:\u001b[94m 0.994540\u001b[35m val_loss:\u001b[94m 0.300785\u001b[35m val_acc:\u001b[94m 92.113565\u001b[35m val_fscore_micro:\u001b[94m 0.921136\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: val_acc improved from 92.05047 to 92.11356, saving file to model/perceptron\\checkpoint_epoch_23.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m24/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.81s \u001b[35mloss:\u001b[94m 0.097974\u001b[35m acc:\u001b[94m 99.454011\u001b[35m fscore_micro:\u001b[94m 0.994540\u001b[35m val_loss:\u001b[94m 0.298575\u001b[35m val_acc:\u001b[94m 91.861199\u001b[35m val_fscore_micro:\u001b[94m 0.918612\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m25/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.90s \u001b[35mloss:\u001b[94m 0.094751\u001b[35m acc:\u001b[94m 99.538009\u001b[35m fscore_micro:\u001b[94m 0.995380\u001b[35m val_loss:\u001b[94m 0.297725\u001b[35m val_acc:\u001b[94m 91.987382\u001b[35m val_fscore_micro:\u001b[94m 0.919874\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m26/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m4.95s \u001b[35mloss:\u001b[94m 0.092009\u001b[35m acc:\u001b[94m 99.622008\u001b[35m fscore_micro:\u001b[94m 0.996220\u001b[35m val_loss:\u001b[94m 0.292738\u001b[35m val_acc:\u001b[94m 92.239748\u001b[35m val_fscore_micro:\u001b[94m 0.922397\u001b[0m\n",
      "Epoch 26: val_acc improved from 92.11356 to 92.23975, saving file to model/perceptron\\checkpoint_epoch_26.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m27/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.87s \u001b[35mloss:\u001b[94m 0.089234\u001b[35m acc:\u001b[94m 99.580008\u001b[35m fscore_micro:\u001b[94m 0.995800\u001b[35m val_loss:\u001b[94m 0.292689\u001b[35m val_acc:\u001b[94m 92.113565\u001b[35m val_fscore_micro:\u001b[94m 0.921136\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m28/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.92s \u001b[35mloss:\u001b[94m 0.086798\u001b[35m acc:\u001b[94m 99.664007\u001b[35m fscore_micro:\u001b[94m 0.996640\u001b[35m val_loss:\u001b[94m 0.289228\u001b[35m val_acc:\u001b[94m 92.176656\u001b[35m val_fscore_micro:\u001b[94m 0.921767\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m29/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.73s \u001b[35mloss:\u001b[94m 0.084341\u001b[35m acc:\u001b[94m 99.748005\u001b[35m fscore_micro:\u001b[94m 0.997480\u001b[35m val_loss:\u001b[94m 0.287684\u001b[35m val_acc:\u001b[94m 92.176656\u001b[35m val_fscore_micro:\u001b[94m 0.921767\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m30/30 \u001b[35mStep: \u001b[36m149/149 \u001b[35m100.00% |\u001b[35m█████████████████████████\u001b[35m|\u001b[32m3.44s \u001b[35mloss:\u001b[94m 0.081991\u001b[35m acc:\u001b[94m 99.748005\u001b[35m fscore_micro:\u001b[94m 0.997480\u001b[35m val_loss:\u001b[94m 0.284572\u001b[35m val_acc:\u001b[94m 92.113565\u001b[35m val_fscore_micro:\u001b[94m 0.921136\u001b[0m\n",
      "Restoring model from model/perceptron\\checkpoint_epoch_26.ckpt\n"
     ]
    }
   ],
   "source": [
    "logging = experiment.train(train_loader, valid_loader, epochs=30, disable_tensorboard=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction with the model\n",
    "Now that the model is trained, we test it on new examples to see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax \n",
    "\n",
    "def get_most_probable_class(sentence, model):\n",
    "    vectorized_sentence = vectorizer.transform([sentence]).todense()\n",
    "    prediction = model(FloatTensor(vectorized_sentence).squeeze(0)).detach()\n",
    "    output = softmax(prediction, dim=0)\n",
    "    max_category_index = np.argmax(output)\n",
    "    max_category = target_categories[max_category_index]\n",
    "    print(\"\\nClassification de la phrase: \", sentence)\n",
    "    print(\"Sorties du réseau de neurones:\", prediction)\n",
    "    print(\"Valeurs obtenues après application de softmax:\", output)\n",
    "    print(\"Meilleure classe: {} qui correspond en sortie au neurone {}\".format(max_category, max_category_index))\n",
    "    return(max_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification de la phrase:  Getzky was a center, not a goaltender\n",
      "Sorties du réseau de neurones: tensor([ 0.0709, -0.0175,  0.0134, -0.0737])\n",
      "Valeurs obtenues après application de softmax: tensor([0.2685, 0.2457, 0.2535, 0.2323])\n",
      "Meilleure classe: rec.autos qui correspond en sortie au neurone 0\n",
      "\n",
      "Classification de la phrase:  Mazda and BMW cars are esthetic \n",
      "Sorties du réseau de neurones: tensor([ 0.7499, -0.3200, -0.1551, -0.2804])\n",
      "Valeurs obtenues après application de softmax: tensor([0.4752, 0.1630, 0.1922, 0.1696])\n",
      "Meilleure classe: rec.autos qui correspond en sortie au neurone 0\n",
      "\n",
      "Classification de la phrase:  Doctor, doctor, gimme the news\n",
      "Sorties du réseau de neurones: tensor([-0.2045,  0.0228,  0.3622, -0.1550])\n",
      "Valeurs obtenues après application de softmax: tensor([0.1973, 0.2476, 0.3477, 0.2073])\n",
      "Meilleure classe: sci.med qui correspond en sortie au neurone 2\n",
      "\n",
      "Classification de la phrase:  Take me to the moon\n",
      "Sorties du réseau de neurones: tensor([-0.0958,  0.0906, -0.0269,  0.0438])\n",
      "Valeurs obtenues après application de softmax: tensor([0.2259, 0.2722, 0.2420, 0.2598])\n",
      "Meilleure classe: rec.sport.hockey qui correspond en sortie au neurone 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rec.autos', 'rec.autos', 'sci.med', 'rec.sport.hockey']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We test the model with a few sentences\n",
    "\n",
    "test_docs = ['Getzky was a center, not a goaltender', \n",
    "             'Mazda and BMW cars are esthetic ',\n",
    "             'Doctor, doctor, gimme the news', \n",
    "             'Take me to the moon']\n",
    "\n",
    "[get_most_probable_class(sentence, perceptron) for sentence in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification de la phrase:  Getzky was a center, not a goaltender but a fantastic hockey player\n",
      "Sorties du réseau de neurones: tensor([-0.1697,  0.6352, -0.2488, -0.2230])\n",
      "Valeurs obtenues après application de softmax: tensor([0.1958, 0.4378, 0.1809, 0.1856])\n",
      "Meilleure classe: rec.sport.hockey qui correspond en sortie au neurone 1\n",
      "\n",
      "Classification de la phrase:  Mazda and BMW are esthetic cars but the motors are quite different\n",
      "Sorties du réseau de neurones: tensor([ 0.7716, -0.2390, -0.2703, -0.2506])\n",
      "Valeurs obtenues après application de softmax: tensor([0.4816, 0.1753, 0.1699, 0.1733])\n",
      "Meilleure classe: rec.autos qui correspond en sortie au neurone 0\n",
      "\n",
      "Classification de la phrase:  Doctor, doctor, gimme the news\n",
      "Sorties du réseau de neurones: tensor([-0.2045,  0.0228,  0.3622, -0.1550])\n",
      "Valeurs obtenues après application de softmax: tensor([0.1973, 0.2476, 0.3477, 0.2073])\n",
      "Meilleure classe: sci.med qui correspond en sortie au neurone 2\n",
      "\n",
      "Classification de la phrase:  Take me to the moon, the sun and planet Mars\n",
      "Sorties du réseau de neurones: tensor([-0.1294,  0.1097, -0.2269,  0.2574])\n",
      "Valeurs obtenues après application de softmax: tensor([0.2151, 0.2732, 0.1951, 0.3167])\n",
      "Meilleure classe: sci.space qui correspond en sortie au neurone 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rec.sport.hockey', 'rec.autos', 'sci.med', 'sci.space']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We test the model with longer sentences, which seems to solve our problem\n",
    "\n",
    "test_docs = ['Getzky was a center, not a goaltender but a fantastic hockey player', \n",
    "             'Mazda and BMW are esthetic cars but the motors are quite different',\n",
    "             'Doctor, doctor, gimme the news', \n",
    "             'Take me to the moon, the sun and planet Mars']\n",
    "\n",
    "[get_most_probable_class(sentence, perceptron) for sentence in test_docs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
