{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de cooccurrences et de collocations\n",
    "NLTK offre des fonctions pour détecter les cooccurrences/collocations d'un texte.\n",
    "\n",
    "Nous avons une cooccurrence lorsque la présence d’un mot dans un texte donne une indication de la présence d’un autre mot. Une collocation est une forme plus restreinte de cooccurrence. Habituellement, une collocation est constituée de mots consécutifs dont la signification ne peut pas être dérivée de la signification des mots individuels.\n",
    "\n",
    "Dans le cadre de ce cours, on ne fait pas de distinction entre les deux concepts et on s'intéresse de manière générale aux mots corrélés entre eux.\n",
    "\n",
    "Nous allons illustrer les différentes techniques présentées dans la capsule vidéo sur le site du cours pour détecter des cooccurrences à partir du corpus de Brown.\n",
    "\n",
    "## 1. Analyse de cooccurrences par la fréquence\n",
    "### Bigrammes\n",
    "\n",
    "La fréquence de N-grammes est un critère qui peut utiliser pour identifier les cooccurrences. Cependant, il est important de faire un bon filtrage pour éliminer le bruit. Car une fréquence élevée n'est pas toujours un bon indicateur. On compare ici les N-grammes les plus fréquents avec ceux obtenus en filtrant à partir des étiquettes grammaticales (POS tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>freq-pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>(Fulton, County)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(,, and)</td>\n",
       "      <td>(Highway, Department)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(., The)</td>\n",
       "      <td>(school, superintendent)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>(Allen, Jr.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(,, the)</td>\n",
       "      <td>(Blue, Ridge)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(., ``)</td>\n",
       "      <td>(Department, source)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(to, the)</td>\n",
       "      <td>(Executive, Committee)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('', .)</td>\n",
       "      <td>(Fulton, legislators)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(;, ;)</td>\n",
       "      <td>(Ivan, Allen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(., He)</td>\n",
       "      <td>(Miller, County)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(?, ?)</td>\n",
       "      <td>(Roads, Authority)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(on, the)</td>\n",
       "      <td>(Rural, Roads)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(and, the)</td>\n",
       "      <td>(State, Highway)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>('', ,)</td>\n",
       "      <td>(State, Welfare)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(,, but)</td>\n",
       "      <td>(Sunday, night)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(., It)</td>\n",
       "      <td>(Superior, Court)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(for, the)</td>\n",
       "      <td>(bond, issue)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(to, be)</td>\n",
       "      <td>(county, school)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(., In)</td>\n",
       "      <td>(federal, funds)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(at, the)</td>\n",
       "      <td>(grand, jury)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(,, he)</td>\n",
       "      <td>(highway, bond)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(with, the)</td>\n",
       "      <td>(new, school)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(of, a)</td>\n",
       "      <td>(pay, raises)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(that, the)</td>\n",
       "      <td>(privilege, resolution)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(from, the)</td>\n",
       "      <td>(revolving, fund)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           freq                  freq-pos\n",
       "0     (of, the)          (Fulton, County)\n",
       "1      (,, and)     (Highway, Department)\n",
       "2      (., The)  (school, superintendent)\n",
       "3     (in, the)              (Allen, Jr.)\n",
       "4      (,, the)             (Blue, Ridge)\n",
       "5       (., ``)      (Department, source)\n",
       "6     (to, the)    (Executive, Committee)\n",
       "7       ('', .)     (Fulton, legislators)\n",
       "8        (;, ;)             (Ivan, Allen)\n",
       "9       (., He)          (Miller, County)\n",
       "10       (?, ?)        (Roads, Authority)\n",
       "11    (on, the)            (Rural, Roads)\n",
       "12   (and, the)          (State, Highway)\n",
       "13      ('', ,)          (State, Welfare)\n",
       "14     (,, but)           (Sunday, night)\n",
       "15      (., It)         (Superior, Court)\n",
       "16   (for, the)             (bond, issue)\n",
       "17     (to, be)          (county, school)\n",
       "18      (., In)          (federal, funds)\n",
       "19    (at, the)             (grand, jury)\n",
       "20      (,, he)           (highway, bond)\n",
       "21  (with, the)             (new, school)\n",
       "22      (of, a)             (pay, raises)\n",
       "23  (that, the)   (privilege, resolution)\n",
       "24  (from, the)         (revolving, fund)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "\n",
    "nb_results = 25\n",
    "brown_words = nltk.corpus.brown.words()\n",
    "brown_tagged_words = nltk.corpus.brown.tagged_words('ca01', tagset='universal')\n",
    "\n",
    "freq_results = dict()\n",
    "\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(brown_words)\n",
    "freq_results[\"freq\"] = finder.nbest(bigram_measures.raw_freq, nb_results)\n",
    "\n",
    "tag_patterns = [(\"NOUN\", \"NOUN\"), (\"ADJ\", \"NOUN\"), (\"VERB\", \"NOUN\")]\n",
    "finder = BigramCollocationFinder.from_words(brown_tagged_words)\n",
    "raw_coocs = finder.nbest(bigram_measures.raw_freq, 1000)\n",
    "filtered_coocs = list()\n",
    "for (w1, tag1), (w2, tag2) in raw_coocs:\n",
    "    if (tag1, tag2) in tag_patterns:\n",
    "        filtered_coocs.append((w1, w2))\n",
    "freq_results[\"freq-pos\"] = filtered_coocs[:nb_results]\n",
    "\n",
    "display(pd.DataFrame(freq_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trigrammes** - On peut faire la même analyse avec les différents N-grammes de mots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>freq-pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('', ?, ?)</td>\n",
       "      <td>(Highway, Department, source)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('', ., ``)</td>\n",
       "      <td>(Ivan, Allen, Jr.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(,, and, the)</td>\n",
       "      <td>(Rural, Roads, Authority)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(., It, is)</td>\n",
       "      <td>(State, Highway, Department)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(., It, was)</td>\n",
       "      <td>(bit, of, trouble)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(., In, the)</td>\n",
       "      <td>(new, school, superintendent)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(?, ?, ``)</td>\n",
       "      <td>(rural, roads, bonds)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(., ``, I)</td>\n",
       "      <td>($10, per, day)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('', !, !)</td>\n",
       "      <td>(Alpharetta, prison, farms)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('', ,, he)</td>\n",
       "      <td>(Ask, jail, deputies)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(., He, was)</td>\n",
       "      <td>(Atlanta, Bar, Association)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(;, ;, and)</td>\n",
       "      <td>(Atlanta, Police, Department)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(,, however, ,)</td>\n",
       "      <td>(B., D., Pelham)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(the, United, States)</td>\n",
       "      <td>(Barber, of, Commerce)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(one, of, the)</td>\n",
       "      <td>(Blue, Ridge, meeting)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>('', ., The)</td>\n",
       "      <td>(Board, of, Education)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(said, ., ``)</td>\n",
       "      <td>(Chairman, James, W.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(;, ;, the)</td>\n",
       "      <td>(Cheshire, of, Griffin)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(said, ,, ``)</td>\n",
       "      <td>(City, of, Atlanta)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(,, in, the)</td>\n",
       "      <td>(Colquitt, Policeman, Tom)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(,, he, said)</td>\n",
       "      <td>(County, Rep., B.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(as, well, as)</td>\n",
       "      <td>(Court, Judge, Durwood)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>('', ., He)</td>\n",
       "      <td>(Democratic, Executive, Committee)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(., There, was)</td>\n",
       "      <td>(E., Pelham, Rd.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(,, it, is)</td>\n",
       "      <td>(Fulton, County, Jail)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     freq                            freq-pos\n",
       "0              ('', ?, ?)       (Highway, Department, source)\n",
       "1             ('', ., ``)                  (Ivan, Allen, Jr.)\n",
       "2           (,, and, the)           (Rural, Roads, Authority)\n",
       "3             (., It, is)        (State, Highway, Department)\n",
       "4            (., It, was)                  (bit, of, trouble)\n",
       "5            (., In, the)       (new, school, superintendent)\n",
       "6              (?, ?, ``)               (rural, roads, bonds)\n",
       "7              (., ``, I)                     ($10, per, day)\n",
       "8              ('', !, !)         (Alpharetta, prison, farms)\n",
       "9             ('', ,, he)               (Ask, jail, deputies)\n",
       "10           (., He, was)         (Atlanta, Bar, Association)\n",
       "11            (;, ;, and)       (Atlanta, Police, Department)\n",
       "12        (,, however, ,)                    (B., D., Pelham)\n",
       "13  (the, United, States)              (Barber, of, Commerce)\n",
       "14         (one, of, the)              (Blue, Ridge, meeting)\n",
       "15           ('', ., The)              (Board, of, Education)\n",
       "16          (said, ., ``)               (Chairman, James, W.)\n",
       "17            (;, ;, the)             (Cheshire, of, Griffin)\n",
       "18          (said, ,, ``)                 (City, of, Atlanta)\n",
       "19           (,, in, the)          (Colquitt, Policeman, Tom)\n",
       "20          (,, he, said)                  (County, Rep., B.)\n",
       "21         (as, well, as)             (Court, Judge, Durwood)\n",
       "22            ('', ., He)  (Democratic, Executive, Committee)\n",
       "23        (., There, was)                   (E., Pelham, Rd.)\n",
       "24            (,, it, is)              (Fulton, County, Jail)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.collocations import TrigramAssocMeasures, TrigramCollocationFinder\n",
    "\n",
    "nb_results = 25\n",
    "results = dict()\n",
    "\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "finder = TrigramCollocationFinder.from_words(brown_words)\n",
    "results[\"freq\"] = finder.nbest(trigram_measures.raw_freq, nb_results)\n",
    "\n",
    "# Quelques patrons de POS tags possibles\n",
    "tag_patterns = [(\"NOUN\", \"NOUN\", \"NOUN\"), (\"ADJ\", \"NOUN\", \"NOUN\"), (\"ADJ\", \"ADJ\", \"NOUN\"), \n",
    "                (\"NOUN\", \"ADP\", \"NOUN\"), (\"VERB\", \"NOUN\", \"NOUN\"), (\"VERB\", \"ADP\", \"NOUN\")]\n",
    "finder = TrigramCollocationFinder.from_words(brown_tagged_words)\n",
    "raw_coocs = finder.nbest(trigram_measures.raw_freq, 1000)\n",
    "filtered_coocs = list()\n",
    "for (w1, tag1), (w2, tag2), (w3, tag3) in raw_coocs:\n",
    "    if (tag1, tag2, tag3) in tag_patterns:\n",
    "        filtered_coocs.append((w1, w2, w3))\n",
    "results[\"freq-pos\"] = filtered_coocs[:nb_results]\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse de cooccurrences avec l'information mutuelle\n",
    "On présente ici les résultats obtenus en retenant les bigrammes dont la valeur d'information mutuelle (PMI - Pointwise mutual information) est la plus élevée.\n",
    "\n",
    "On sait que la mesure d'information mutuelle est sensible aux faibles fréquences. On présente également dans le tableau les résultats lorsqu'on filtre selon le nombre d'occurrences d'un bigramme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmi</th>\n",
       "      <th>pmi-filtre-2</th>\n",
       "      <th>pmi-filtre-5</th>\n",
       "      <th>pmi-filtre-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>($10,000-per-year, French-born)</td>\n",
       "      <td>(Ablard, Corne)</td>\n",
       "      <td>(Baton, Rouge)</td>\n",
       "      <td>(Hong, Kong)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>($79.89, nothing-down)</td>\n",
       "      <td>(Agatha, Christie)</td>\n",
       "      <td>(Dolce, Vita)</td>\n",
       "      <td>(Viet, Nam)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>($8.50, tab)</td>\n",
       "      <td>(Averell, Harriman)</td>\n",
       "      <td>(Neutral, Tones)</td>\n",
       "      <td>(Pathet, Lao)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('low, nigras)</td>\n",
       "      <td>(Ballistic, Missile)</td>\n",
       "      <td>(Notre, Dame)</td>\n",
       "      <td>(Simms, Purdew)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.5-mv./m., 50-percent)</td>\n",
       "      <td>(Bon, jour)</td>\n",
       "      <td>(Sante, Fe)</td>\n",
       "      <td>(El, Paso)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.78, mEq)</td>\n",
       "      <td>(Bryn, Mawr)</td>\n",
       "      <td>(deja, vue)</td>\n",
       "      <td>(Lo, Shu)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1,100, circumscriptions)</td>\n",
       "      <td>(Champs, Elysees)</td>\n",
       "      <td>(boa, constrictor)</td>\n",
       "      <td>(Internal, Revenue)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1,257,700, non-farm)</td>\n",
       "      <td>(Citizens', Councils)</td>\n",
       "      <td>(Gratt, Shafer)</td>\n",
       "      <td>(Puerto, Rico)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(11-inch, headroom)</td>\n",
       "      <td>(Computing, Allotments)</td>\n",
       "      <td>(Pulley, Bey)</td>\n",
       "      <td>(Saxon, Shore)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(11-shot, hammerless)</td>\n",
       "      <td>(Cooch, Terpers)</td>\n",
       "      <td>(Walnut, Trees)</td>\n",
       "      <td>(Export-Import, Bank)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(12-inch, electromagnet)</td>\n",
       "      <td>(Corpus, Christi)</td>\n",
       "      <td>(Childhood's, End)</td>\n",
       "      <td>(carbon, tetrachloride)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1200, Larimer)</td>\n",
       "      <td>(Distilled, Spirits)</td>\n",
       "      <td>(cu., ft.)</td>\n",
       "      <td>(unwed, mothers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(147,000, gpd)</td>\n",
       "      <td>(Gute, ruh)</td>\n",
       "      <td>(Yugoslav, Claims)</td>\n",
       "      <td>(Armed, Forces)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(15,500-lb., fork-lift)</td>\n",
       "      <td>(H.M., Chadwick)</td>\n",
       "      <td>(Scottish, Rite)</td>\n",
       "      <td>(Virgin, Islands)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(150-milliampere, flashlight-type)</td>\n",
       "      <td>(Irina, Kolpakova)</td>\n",
       "      <td>(causal, efficacy)</td>\n",
       "      <td>(Middle, Ages)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(1671, Nakoma)</td>\n",
       "      <td>(Jehovah's, Witnesses)</td>\n",
       "      <td>(Oakwood, Heights)</td>\n",
       "      <td>(oxidation, pond)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(182, scholastics)</td>\n",
       "      <td>(Luang, Prabang)</td>\n",
       "      <td>(U, Thant)</td>\n",
       "      <td>(Utopian, communism)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(200-odd, officeholders)</td>\n",
       "      <td>(Mardi, Gras)</td>\n",
       "      <td>(Hong, Kong)</td>\n",
       "      <td>(Gross, Income)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(21-year, typhoon)</td>\n",
       "      <td>(McGeorge, Bundy)</td>\n",
       "      <td>(Diana, Beauclerk)</td>\n",
       "      <td>(Air, Force)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(220-yard, par-3)</td>\n",
       "      <td>(Nogay, Tartary)</td>\n",
       "      <td>(Gyp, Carmer)</td>\n",
       "      <td>(barbed, wire)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(2269, Serra)</td>\n",
       "      <td>(Oatnut, Grits)</td>\n",
       "      <td>(Patrice, Lumumba)</td>\n",
       "      <td>(Blue, Throat)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(25-gallon, long-cruise)</td>\n",
       "      <td>(Pee, Wee)</td>\n",
       "      <td>(Marvin, Goulding)</td>\n",
       "      <td>(minimal, polynomial)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(2705, Fitzhugh)</td>\n",
       "      <td>(Phi, Beta)</td>\n",
       "      <td>(Brian, Thayer)</td>\n",
       "      <td>(nonspecific, staining)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(2731, Pall)</td>\n",
       "      <td>(Po', Chavis)</td>\n",
       "      <td>(Space, Merchants)</td>\n",
       "      <td>(Los, Angeles)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(3.8, mEq.)</td>\n",
       "      <td>(Reader's, Digest)</td>\n",
       "      <td>(bacterial, diarrhea)</td>\n",
       "      <td>(Linda, Kay)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   pmi             pmi-filtre-2  \\\n",
       "0      ($10,000-per-year, French-born)          (Ablard, Corne)   \n",
       "1               ($79.89, nothing-down)       (Agatha, Christie)   \n",
       "2                         ($8.50, tab)      (Averell, Harriman)   \n",
       "3                       ('low, nigras)     (Ballistic, Missile)   \n",
       "4             (0.5-mv./m., 50-percent)              (Bon, jour)   \n",
       "5                          (0.78, mEq)             (Bryn, Mawr)   \n",
       "6            (1,100, circumscriptions)        (Champs, Elysees)   \n",
       "7                (1,257,700, non-farm)    (Citizens', Councils)   \n",
       "8                  (11-inch, headroom)  (Computing, Allotments)   \n",
       "9                (11-shot, hammerless)         (Cooch, Terpers)   \n",
       "10            (12-inch, electromagnet)        (Corpus, Christi)   \n",
       "11                     (1200, Larimer)     (Distilled, Spirits)   \n",
       "12                      (147,000, gpd)              (Gute, ruh)   \n",
       "13             (15,500-lb., fork-lift)         (H.M., Chadwick)   \n",
       "14  (150-milliampere, flashlight-type)       (Irina, Kolpakova)   \n",
       "15                      (1671, Nakoma)   (Jehovah's, Witnesses)   \n",
       "16                  (182, scholastics)         (Luang, Prabang)   \n",
       "17            (200-odd, officeholders)            (Mardi, Gras)   \n",
       "18                  (21-year, typhoon)        (McGeorge, Bundy)   \n",
       "19                   (220-yard, par-3)         (Nogay, Tartary)   \n",
       "20                       (2269, Serra)          (Oatnut, Grits)   \n",
       "21            (25-gallon, long-cruise)               (Pee, Wee)   \n",
       "22                    (2705, Fitzhugh)              (Phi, Beta)   \n",
       "23                        (2731, Pall)            (Po', Chavis)   \n",
       "24                         (3.8, mEq.)       (Reader's, Digest)   \n",
       "\n",
       "             pmi-filtre-5            pmi-filtre-10  \n",
       "0          (Baton, Rouge)             (Hong, Kong)  \n",
       "1           (Dolce, Vita)              (Viet, Nam)  \n",
       "2        (Neutral, Tones)            (Pathet, Lao)  \n",
       "3           (Notre, Dame)          (Simms, Purdew)  \n",
       "4             (Sante, Fe)               (El, Paso)  \n",
       "5             (deja, vue)                (Lo, Shu)  \n",
       "6      (boa, constrictor)      (Internal, Revenue)  \n",
       "7         (Gratt, Shafer)           (Puerto, Rico)  \n",
       "8           (Pulley, Bey)           (Saxon, Shore)  \n",
       "9         (Walnut, Trees)    (Export-Import, Bank)  \n",
       "10     (Childhood's, End)  (carbon, tetrachloride)  \n",
       "11             (cu., ft.)         (unwed, mothers)  \n",
       "12     (Yugoslav, Claims)          (Armed, Forces)  \n",
       "13       (Scottish, Rite)        (Virgin, Islands)  \n",
       "14     (causal, efficacy)           (Middle, Ages)  \n",
       "15     (Oakwood, Heights)        (oxidation, pond)  \n",
       "16             (U, Thant)     (Utopian, communism)  \n",
       "17           (Hong, Kong)          (Gross, Income)  \n",
       "18     (Diana, Beauclerk)             (Air, Force)  \n",
       "19          (Gyp, Carmer)           (barbed, wire)  \n",
       "20     (Patrice, Lumumba)           (Blue, Throat)  \n",
       "21     (Marvin, Goulding)    (minimal, polynomial)  \n",
       "22        (Brian, Thayer)  (nonspecific, staining)  \n",
       "23     (Space, Merchants)           (Los, Angeles)  \n",
       "24  (bacterial, diarrhea)             (Linda, Kay)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_results = 25\n",
    "\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(brown_words)\n",
    "\n",
    "pmi_results = dict()\n",
    "pmi_results[\"pmi\"] = finder.nbest(bigram_measures.pmi, nb_results)\n",
    "\n",
    "finder.apply_freq_filter(2)\n",
    "pmi_results[\"pmi-filtre-2\"] = finder.nbest(bigram_measures.pmi, nb_results)\n",
    "\n",
    "finder.apply_freq_filter(5)\n",
    "pmi_results[\"pmi-filtre-5\"] = finder.nbest(bigram_measures.pmi, nb_results)\n",
    "\n",
    "finder.apply_freq_filter(10)\n",
    "pmi_results[\"pmi-filtre-10\"] = finder.nbest(bigram_measures.pmi, nb_results)\n",
    "\n",
    "display(pd.DataFrame(pmi_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse de cooccurrences avec d'autres mesures statistiques\n",
    "Le chapitre 5 du livre de Chris Manning présente d'autres mesures qui peuvent être utilisées pour détecter/filtrer les cooccurences. NLTK offre la plupart de ces mesures. Le tableau suivant présente un échantillon des résultats obtenus avec ces mesures. Comme on peut le voir, la qualité des résultats est très variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student</th>\n",
       "      <th>likelihood ratio</th>\n",
       "      <th>chi sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>(., The)</td>\n",
       "      <td>(Baton, Rouge)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(., The)</td>\n",
       "      <td>(;, ;)</td>\n",
       "      <td>(Dolce, Vita)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(,, and)</td>\n",
       "      <td>(?, ?)</td>\n",
       "      <td>(Hong, Kong)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>(of, the)</td>\n",
       "      <td>(Lo, Shu)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(., ``)</td>\n",
       "      <td>(., He)</td>\n",
       "      <td>(Notre, Dame)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(;, ;)</td>\n",
       "      <td>(., ``)</td>\n",
       "      <td>(deja, vue)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('', .)</td>\n",
       "      <td>(in, the)</td>\n",
       "      <td>(Los, Angeles)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(., He)</td>\n",
       "      <td>(,, and)</td>\n",
       "      <td>(Puerto, Rico)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(?, ?)</td>\n",
       "      <td>(., It)</td>\n",
       "      <td>(Neutral, Tones)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(., It)</td>\n",
       "      <td>('', .)</td>\n",
       "      <td>(Viet, Nam)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(on, the)</td>\n",
       "      <td>(., In)</td>\n",
       "      <td>(Yugoslav, Claims)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(,, but)</td>\n",
       "      <td>(!, !)</td>\n",
       "      <td>(Gratt, Shafer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(., In)</td>\n",
       "      <td>(,, but)</td>\n",
       "      <td>(Pulley, Bey)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(to, be)</td>\n",
       "      <td>(., But)</td>\n",
       "      <td>(Walnut, Trees)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>('', ,)</td>\n",
       "      <td>(United, States)</td>\n",
       "      <td>(United, States)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(to, the)</td>\n",
       "      <td>(., This)</td>\n",
       "      <td>(Sante, Fe)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(., But)</td>\n",
       "      <td>(to, be)</td>\n",
       "      <td>(Simms, Purdew)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(at, the)</td>\n",
       "      <td>(on, the)</td>\n",
       "      <td>(boa, constrictor)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(., This)</td>\n",
       "      <td>(,, ,)</td>\n",
       "      <td>(Armed, Forces)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(from, the)</td>\n",
       "      <td>(had, been)</td>\n",
       "      <td>(carbon, tetrachloride)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        student  likelihood ratio                   chi sq\n",
       "0     (of, the)          (., The)           (Baton, Rouge)\n",
       "1      (., The)            (;, ;)            (Dolce, Vita)\n",
       "2      (,, and)            (?, ?)             (Hong, Kong)\n",
       "3     (in, the)         (of, the)                (Lo, Shu)\n",
       "4       (., ``)           (., He)            (Notre, Dame)\n",
       "5        (;, ;)           (., ``)              (deja, vue)\n",
       "6       ('', .)         (in, the)           (Los, Angeles)\n",
       "7       (., He)          (,, and)           (Puerto, Rico)\n",
       "8        (?, ?)           (., It)         (Neutral, Tones)\n",
       "9       (., It)           ('', .)              (Viet, Nam)\n",
       "10    (on, the)           (., In)       (Yugoslav, Claims)\n",
       "11     (,, but)            (!, !)          (Gratt, Shafer)\n",
       "12      (., In)          (,, but)            (Pulley, Bey)\n",
       "13     (to, be)          (., But)          (Walnut, Trees)\n",
       "14      ('', ,)  (United, States)         (United, States)\n",
       "15    (to, the)         (., This)              (Sante, Fe)\n",
       "16     (., But)          (to, be)          (Simms, Purdew)\n",
       "17    (at, the)         (on, the)       (boa, constrictor)\n",
       "18    (., This)            (,, ,)          (Armed, Forces)\n",
       "19  (from, the)       (had, been)  (carbon, tetrachloride)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_results = 20\n",
    "\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(brown_words)\n",
    "\n",
    "other_results = dict()\n",
    "finder.apply_freq_filter(5)\n",
    "other_results[\"student\"] = finder.nbest(bigram_measures.student_t, nb_results)\n",
    "other_results[\"likelihood ratio\"] = finder.nbest(bigram_measures.likelihood_ratio, nb_results)\n",
    "other_results[\"chi sq\"] = finder.nbest(bigram_measures.chi_sq, nb_results)\n",
    "\n",
    "display(pd.DataFrame(other_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut toutefois améliorer un peu les résultats en filtrant les mots outils (stop words) et les caractères individuels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student</th>\n",
       "      <th>likelihood ratio</th>\n",
       "      <th>chi sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(United, States)</td>\n",
       "      <td>(United, States)</td>\n",
       "      <td>(Baton, Rouge)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(New, York)</td>\n",
       "      <td>(New, York)</td>\n",
       "      <td>(Dolce, Vita)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(per, cent)</td>\n",
       "      <td>(per, cent)</td>\n",
       "      <td>(Hong, Kong)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(years, ago)</td>\n",
       "      <td>(Rhode, Island)</td>\n",
       "      <td>(Lo, Shu)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('', --)</td>\n",
       "      <td>(years, ago)</td>\n",
       "      <td>(Notre, Dame)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Rhode, Island)</td>\n",
       "      <td>(U., S.)</td>\n",
       "      <td>(deja, vue)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(could, see)</td>\n",
       "      <td>(Los, Angeles)</td>\n",
       "      <td>(Los, Angeles)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(``, I'm)</td>\n",
       "      <td>(White, House)</td>\n",
       "      <td>(Puerto, Rico)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(``, Well)</td>\n",
       "      <td>(Peace, Corps)</td>\n",
       "      <td>(Neutral, Tones)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(``, Oh)</td>\n",
       "      <td>(World, War)</td>\n",
       "      <td>(Viet, Nam)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(last, year)</td>\n",
       "      <td>(San, Francisco)</td>\n",
       "      <td>(Yugoslav, Claims)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(White, House)</td>\n",
       "      <td>(United, Nations)</td>\n",
       "      <td>(Gratt, Shafer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(first, time)</td>\n",
       "      <td>(General, Motors)</td>\n",
       "      <td>(Pulley, Bey)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(even, though)</td>\n",
       "      <td>(fiscal, year)</td>\n",
       "      <td>(Walnut, Trees)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(World, War)</td>\n",
       "      <td>(Du, Pont)</td>\n",
       "      <td>(United, States)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(U., S.)</td>\n",
       "      <td>(``, Well)</td>\n",
       "      <td>(Sante, Fe)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(fiscal, year)</td>\n",
       "      <td>(``, Oh)</td>\n",
       "      <td>(Simms, Purdew)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(two, years)</td>\n",
       "      <td>(could, see)</td>\n",
       "      <td>(boa, constrictor)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(last, night)</td>\n",
       "      <td>(New, Orleans)</td>\n",
       "      <td>(Armed, Forces)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(``, I'll)</td>\n",
       "      <td>(Civil, War)</td>\n",
       "      <td>(carbon, tetrachloride)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             student   likelihood ratio                   chi sq\n",
       "0   (United, States)   (United, States)           (Baton, Rouge)\n",
       "1        (New, York)        (New, York)            (Dolce, Vita)\n",
       "2        (per, cent)        (per, cent)             (Hong, Kong)\n",
       "3       (years, ago)    (Rhode, Island)                (Lo, Shu)\n",
       "4           ('', --)       (years, ago)            (Notre, Dame)\n",
       "5    (Rhode, Island)           (U., S.)              (deja, vue)\n",
       "6       (could, see)     (Los, Angeles)           (Los, Angeles)\n",
       "7          (``, I'm)     (White, House)           (Puerto, Rico)\n",
       "8         (``, Well)     (Peace, Corps)         (Neutral, Tones)\n",
       "9           (``, Oh)       (World, War)              (Viet, Nam)\n",
       "10      (last, year)   (San, Francisco)       (Yugoslav, Claims)\n",
       "11    (White, House)  (United, Nations)          (Gratt, Shafer)\n",
       "12     (first, time)  (General, Motors)            (Pulley, Bey)\n",
       "13    (even, though)     (fiscal, year)          (Walnut, Trees)\n",
       "14      (World, War)         (Du, Pont)         (United, States)\n",
       "15          (U., S.)         (``, Well)              (Sante, Fe)\n",
       "16    (fiscal, year)           (``, Oh)          (Simms, Purdew)\n",
       "17      (two, years)       (could, see)       (boa, constrictor)\n",
       "18     (last, night)     (New, Orleans)          (Armed, Forces)\n",
       "19        (``, I'll)       (Civil, War)  (carbon, tetrachloride)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ignored_words = nltk.corpus.stopwords.words('english')\n",
    "finder.apply_word_filter(lambda w: len(w) < 2 or w.lower() in ignored_words)\n",
    "\n",
    "other_results = dict()\n",
    "other_results[\"student\"] = finder.nbest(bigram_measures.student_t, nb_results)\n",
    "other_results[\"likelihood ratio\"] = finder.nbest(bigram_measures.likelihood_ratio, nb_results)\n",
    "other_results[\"chi sq\"] = finder.nbest(bigram_measures.chi_sq, nb_results)\n",
    "\n",
    "display(pd.DataFrame(other_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cooccurrences à l'intérieur d'une fenêtre de mots\n",
    "On termine en rappelant que les cooccurrences n'ont pas à être des mots consécutifs. Ils peuvent être dans une même phrase ou à l'intérieur d'une fenêtre de mots. On présente ici quelques résultats pour illustrer les relations entre ces mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fenetre-5</th>\n",
       "      <th>Fenetre-10</th>\n",
       "      <th>Fenetre-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Baton, Rouge)</td>\n",
       "      <td>(Consulting, Engineer)</td>\n",
       "      <td>(Farmer, dell)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Dolce, Vita)</td>\n",
       "      <td>(Hwang, Pah)</td>\n",
       "      <td>(po'k, skippers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Lauro, Bosis)</td>\n",
       "      <td>(vs, vs)</td>\n",
       "      <td>(Consulting, Engineer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Mollie, Mutton)</td>\n",
       "      <td>(Presiding, Elder)</td>\n",
       "      <td>(Consulting, Senior)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Neutral, Tones)</td>\n",
       "      <td>(Baton, Rouge)</td>\n",
       "      <td>(Dealing, faro)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Notre, Dame)</td>\n",
       "      <td>(Dolce, Vita)</td>\n",
       "      <td>(conformational, entropy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Sante, Fe)</td>\n",
       "      <td>(Mollie, Mutton)</td>\n",
       "      <td>(Engineer, Senior)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(deja, vue)</td>\n",
       "      <td>(Lauro, Bosis)</td>\n",
       "      <td>(Engineer, Engineer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(boa, constrictor)</td>\n",
       "      <td>(Notre, Dame)</td>\n",
       "      <td>(vs, vs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Gratt, Shafer)</td>\n",
       "      <td>(Neutral, Tones)</td>\n",
       "      <td>(Hoot, Mon-Goddess)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Pulley, Bey)</td>\n",
       "      <td>(Unifil, loom)</td>\n",
       "      <td>(Beech, Pasture)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Walnut, Trees)</td>\n",
       "      <td>(tents, tents)</td>\n",
       "      <td>(Duncan, Phyfe)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(whereof, hereunto)</td>\n",
       "      <td>(deja, vue)</td>\n",
       "      <td>(Hwang, Pah)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Childhood's, End)</td>\n",
       "      <td>(Sante, Fe)</td>\n",
       "      <td>(fermented, fermented)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(cu., ft.)</td>\n",
       "      <td>(DA, DC)</td>\n",
       "      <td>(pas, deux)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Yugoslav, Claims)</td>\n",
       "      <td>(Kenneth, Rexroth)</td>\n",
       "      <td>(Consulting, Electrical)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Scottish, Rite)</td>\n",
       "      <td>(Liston, Liston)</td>\n",
       "      <td>(ciliated, protozoa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(causal, efficacy)</td>\n",
       "      <td>(boa, constrictor)</td>\n",
       "      <td>(acetonemia, ketosis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Oakwood, Heights)</td>\n",
       "      <td>(Gratt, Shafer)</td>\n",
       "      <td>(tents, tents)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(U, Thant)</td>\n",
       "      <td>(Jossy, Plains)</td>\n",
       "      <td>(Mollie, Mutton)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(Hong, Kong)</td>\n",
       "      <td>(Pulley, Bey)</td>\n",
       "      <td>(tents, Pop)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(Diana, Beauclerk)</td>\n",
       "      <td>(Walnut, Trees)</td>\n",
       "      <td>(Presiding, Elder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Gyp, Carmer)</td>\n",
       "      <td>(whereof, hereunto)</td>\n",
       "      <td>(Hoot, 2:30.3-:36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(Patrice, Lumumba)</td>\n",
       "      <td>(Childhood's, End)</td>\n",
       "      <td>(Knight, Trader)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(Marvin, Goulding)</td>\n",
       "      <td>(Yugoslav, Claims)</td>\n",
       "      <td>(sodium, tripolyphosphate)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fenetre-5              Fenetre-10                  Fenetre-20\n",
       "0        (Baton, Rouge)  (Consulting, Engineer)              (Farmer, dell)\n",
       "1         (Dolce, Vita)            (Hwang, Pah)            (po'k, skippers)\n",
       "2        (Lauro, Bosis)                (vs, vs)      (Consulting, Engineer)\n",
       "3      (Mollie, Mutton)      (Presiding, Elder)        (Consulting, Senior)\n",
       "4      (Neutral, Tones)          (Baton, Rouge)             (Dealing, faro)\n",
       "5         (Notre, Dame)           (Dolce, Vita)   (conformational, entropy)\n",
       "6           (Sante, Fe)        (Mollie, Mutton)          (Engineer, Senior)\n",
       "7           (deja, vue)          (Lauro, Bosis)        (Engineer, Engineer)\n",
       "8    (boa, constrictor)           (Notre, Dame)                    (vs, vs)\n",
       "9       (Gratt, Shafer)        (Neutral, Tones)         (Hoot, Mon-Goddess)\n",
       "10        (Pulley, Bey)          (Unifil, loom)            (Beech, Pasture)\n",
       "11      (Walnut, Trees)          (tents, tents)             (Duncan, Phyfe)\n",
       "12  (whereof, hereunto)             (deja, vue)                (Hwang, Pah)\n",
       "13   (Childhood's, End)             (Sante, Fe)      (fermented, fermented)\n",
       "14           (cu., ft.)                (DA, DC)                 (pas, deux)\n",
       "15   (Yugoslav, Claims)      (Kenneth, Rexroth)    (Consulting, Electrical)\n",
       "16     (Scottish, Rite)        (Liston, Liston)        (ciliated, protozoa)\n",
       "17   (causal, efficacy)      (boa, constrictor)       (acetonemia, ketosis)\n",
       "18   (Oakwood, Heights)         (Gratt, Shafer)              (tents, tents)\n",
       "19           (U, Thant)         (Jossy, Plains)            (Mollie, Mutton)\n",
       "20         (Hong, Kong)           (Pulley, Bey)                (tents, Pop)\n",
       "21   (Diana, Beauclerk)         (Walnut, Trees)          (Presiding, Elder)\n",
       "22        (Gyp, Carmer)     (whereof, hereunto)          (Hoot, 2:30.3-:36)\n",
       "23   (Patrice, Lumumba)      (Childhood's, End)            (Knight, Trader)\n",
       "24   (Marvin, Goulding)      (Yugoslav, Claims)  (sodium, tripolyphosphate)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cooc_within_window(words, window_size=20, nb_results=25, min_freq=5):\n",
    "    finder = BigramCollocationFinder.from_words(words, window_size=window_size)\n",
    "    finder.apply_freq_filter(min_freq)\n",
    "    ignored_words = nltk.corpus.stopwords.words('english')\n",
    "    finder.apply_word_filter(lambda w: w.lower() in ignored_words)\n",
    "    return finder.nbest(bigram_measures.pmi, nb_results)\n",
    "\n",
    "window_results = dict()\n",
    "window_results[\"Fenetre-5\"] = cooc_within_window(brown_words, window_size=5)\n",
    "window_results[\"Fenetre-10\"] = cooc_within_window(brown_words, window_size=10)\n",
    "window_results[\"Fenetre-20\"] = cooc_within_window(brown_words, window_size=20)\n",
    "\n",
    "display(pd.DataFrame(window_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
