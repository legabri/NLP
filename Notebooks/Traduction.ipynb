{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traduction statistique avec NLTK - Quelques concepts\n",
    "\n",
    "## 1. Création du bitexte anglais-français\n",
    "\n",
    "La traduction statistique utilise des textes parallèles en 2 langues pour apprendre comment traduire des textes. Un bitexte est un corpus dont le texte est disponible en 2 langues. On peut alors aligner les phrases de ces textes et, par la suite, trouver les mots qui correspondent de part et d'autre.\n",
    "\n",
    "Pour cet exemple, nous avons récupéré sur le Web un corpus parallèle anglais-français de 100 000 phrases. On débute notre exemple en montant en mémoire ces phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases anglaises:  100000\n",
      "Nombre de phrases françaises:  100000\n",
      "Quelques phrases parallèles:\n",
      "\n",
      "['This', 'is', 'Bill', 'Lange.', \"I'm\", 'Dave', 'Gallo.']\n",
      "['Voici', 'Bill', 'Lange.', 'Je', 'suis', 'Dave', 'Gallo.']\n",
      "\n",
      "['And', \"we're\", 'going', 'to', 'tell', 'you', 'some', 'stories', 'from', 'the', 'sea', 'here', 'in', 'video.']\n",
      "['Nous', 'allons', 'vous', 'raconter', 'quelques', 'histoires', 'de', 'la', 'mer', 'en', 'vidéo.']\n",
      "\n",
      "[\"We've\", 'got', 'some', 'of', 'the', 'most', 'incredible', 'video', 'of', 'Titanic', \"that's\", 'ever', 'been', 'seen,', 'and', \"we're\", 'not', 'going', 'to', 'show', 'you', 'any', 'of', 'it.']\n",
      "['Nous', 'avons', 'des', 'vidéos', 'du', 'Titanic', 'parmi', 'les', 'plus', 'spectaculaires', 'jamais', 'vues.', 'et', 'nous', \"n'allons\", 'pas', 'vous', 'en', 'montrer', 'une', 'image.']\n",
      "\n",
      "['The', 'truth', 'of', 'the', 'matter', 'is', 'that', 'the', 'Titanic', '--', 'even', 'though', \"it's\", 'breaking', 'all', 'sorts', 'of', 'box', 'office', 'records', '--', \"it's\", 'not', 'the', 'most', 'exciting', 'story', 'from', 'the', 'sea.']\n",
      "['La', 'vérité', 'est', 'que', 'le', 'Titanic', '--', 'même', \"s'il\", 'continue', 'de', 'battre', 'toutes', 'les', 'records', 'de', 'recettes', '--', \"n'est\", 'pas', \"l'histoire\", 'la', 'plus', 'passionnante.']\n",
      "\n",
      "['And', 'the', 'problem,', 'I', 'think,', 'is', 'that', 'we', 'take', 'the', 'ocean', 'for', 'granted.']\n",
      "['Le', 'problème,', 'je', 'crois,', 'est', \"qu'on\", 'tient', \"l'océan\", 'pour', 'acquis.']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "    \n",
    "with open(\"./data/train_en.json\") as en_file:\n",
    "    eng_sentences = json.load(en_file)\n",
    "with open(\"./data/train_fr.json\") as fr_file:\n",
    "    fr_sentences = json.load(fr_file)\n",
    "\n",
    "print(\"Nombre de phrases anglaises: \", len(eng_sentences))\n",
    "print(\"Nombre de phrases françaises: \", len(fr_sentences))\n",
    "\n",
    "print(\"Quelques phrases parallèles:\")\n",
    "for i in range(5):\n",
    "    print(\"\\n{}\".format(eng_sentences[i]))\n",
    "    print(fr_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Alignement de phrases\n",
    "\n",
    "L'alignement de phrases est simple pour cet exemple. Les 2 listes contiennent le même de phrases et les phrases à la position X des listes sont alignées ensemblent. La classe AlignedSent de NLTK permet de conserver les paires de phrases et les informations sur l'alignement de ces phrases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase cible: ['Voici', 'Bill', 'Lange.', 'Je', 'suis', 'Dave', 'Gallo.']\n",
      "Alignée avec phrase source: ['This', 'is', 'Bill', 'Lange.', \"I'm\", 'Dave', 'Gallo.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.api import AlignedSent\n",
    "\n",
    "aligned_text = []  \n",
    "for i in range(len(eng_sentences)):\n",
    "    al_sent = AlignedSent(fr_sentences[i], eng_sentences[i])\n",
    "    aligned_text.append(al_sent)\n",
    "\n",
    "sentence_alignment =  aligned_text[0]\n",
    "print(\"Phrase cible:\",sentence_alignment.words)\n",
    "print(\"Alignée avec phrase source:\", sentence_alignment.mots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entraînement de modèles de traduction IBM\n",
    "\n",
    "NLTK offre des implémentations des modèles IBM (1 à 5). Nous allons nous limité ici au modèle IBM qui est présenté dans le matériel du cours. C'est le modèle le plus simple. Il permet toutefois de comprendre les principaux concepts reliés à l'alignement de mots individuels.\n",
    "\n",
    "La première étape consiste à prendre toutes les paires de phrases alignées ensemble et à obtenir le modèle de traduction. Ce modèle donne la probabilité qu'un mot dans une langue source soit traduit par un autre mot dans une langue cible. Les paramètres du modèle sont appris à l'aide d'un algorithme d'apprentissage non supervisé de type \"Expectation-Maximization\" (voir matériel du cours pour plus de détail). Cet algorithme itératif met à jour à chaque étape les probabilités de traduction du modèle. On limite ici le nombre d'itération à 5. L'entraînement avec 100 000 pairs de phrases prend environ 8 minutes sur mon Macbook Pro (qui date de plusieurs années). Donc la patience est de mise lorsque vous roulerez cet exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle IBM1...\n",
      "Training complete\n",
      "Entraînement complété en %s seconds ---\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.ibm1 import IBMModel1\n",
    "import time\n",
    "\n",
    "print(\"Entraînement du modèle IBM1...\")\n",
    "start_time = time.time()\n",
    "nb_iterations = 5\n",
    "ibm_model1 = IBMModel1(aligned_text, nb_iterations)\n",
    "print(\"Training complete\")\n",
    "print(\"Entraînement complété en %s seconds ---\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un petit bout de code que vous pourrez réutiliser si vous voulez sauvegarder le modèle pour éviter le reconstruire à chaque fois que vous roulez ce notebook. À noter que le modèle prend environ 2000 MB de mémoire à stocker dans un fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "import gzip\n",
    "\n",
    "fi = open('./ibm_model1.pkl','wb')\n",
    "pickle.dump(ibm_model1,fi)\n",
    "fi.close()\n",
    "\n",
    "# pour monter en mémoire le modèle par la suite\n",
    "with open('./ibm_model1.pkl', 'rb') as pickle_file:\n",
    "    ibm_model1 = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Les paramètres du modèle de traduction IBM1\n",
    "\n",
    "Lors de l'apprentissage du modèle IBM1, l'algorithme a estimé les probabilités que les mots dans la langue source soit traduits par des mots de la langue cible. Autrement dit, les probabilités de traduction de mots individuels. En voici quelques exemples pour notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t(langue, language) =  0.38590347851494206\n",
      "t(langue, Null) =  2.989972362038413e-11\n"
     ]
    }
   ],
   "source": [
    "print(\"t(langue, language) = \", ibm_model1.translation_table['langue']['language'])\n",
    "print(\"t(langue, Null) = \", ibm_model1.translation_table['langue'][None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t(fr,en)</th>\n",
       "      <th>faire</th>\n",
       "      <th>fait</th>\n",
       "      <th>prendre</th>\n",
       "      <th>prend</th>\n",
       "      <th>décider</th>\n",
       "      <th>choisir</th>\n",
       "      <th>obtenir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make</td>\n",
       "      <td>0.400846</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>makes</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.384003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do</td>\n",
       "      <td>0.501579</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>does</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.214417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take</td>\n",
       "      <td>0.017566</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.430470</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>takes</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.452807</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decide</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.521549</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>choose</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.583688</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pick</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.130703</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.141101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>get</td>\n",
       "      <td>0.047224</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t(fr,en)     faire      fait   prendre     prend   décider   choisir  \\\n",
       "0     make  0.400846  0.004968  0.000542  0.000002  0.000000  0.000000   \n",
       "1    makes  0.000883  0.384003  0.000000  0.000003  0.000010  0.000000   \n",
       "2       do  0.501579  0.006606  0.000011  0.000000  0.000000  0.000000   \n",
       "3     does  0.001681  0.214417  0.000000  0.000000  0.000010  0.000010   \n",
       "4     take  0.017566  0.000897  0.430470  0.001284  0.000000  0.000000   \n",
       "5    takes  0.000942  0.001038  0.000025  0.452807  0.000010  0.000000   \n",
       "6   decide  0.001348  0.000000  0.000000  0.000010  0.521549  0.000338   \n",
       "7   choose  0.001309  0.000124  0.002855  0.000000  0.000004  0.583688   \n",
       "8     pick  0.000292  0.000339  0.130703  0.000010  0.000010  0.141101   \n",
       "9      get  0.047224  0.001153  0.000100  0.000001  0.000000  0.000000   \n",
       "\n",
       "    obtenir  \n",
       "0  0.000001  \n",
       "1  0.000010  \n",
       "2  0.000003  \n",
       "3  0.000000  \n",
       "4  0.000001  \n",
       "5  0.000000  \n",
       "6  0.000010  \n",
       "7  0.000010  \n",
       "8  0.000000  \n",
       "9  0.045078  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_translation_dataframe(list_fr, list_en):\n",
    "    verb_trans_probs = list()\n",
    "    for word_en in list_en:\n",
    "        parameters = dict()\n",
    "        parameters['t(fr,en)'] =  word_en\n",
    "        for word_fr in list_fr:\n",
    "            parameters[word_fr] = round(ibm_model1.translation_table[word_fr][word_en], 6)\n",
    "        verb_trans_probs.append(parameters)\n",
    "    return pd.DataFrame(verb_trans_probs)\n",
    "    \n",
    "verbs_en = [\"make\", \"makes\", \"do\", \"does\", \"take\", \"takes\", \"decide\", \"choose\", \"pick\", \"get\"]\n",
    "verbs_fr = [\"faire\", \"fait\", \"prendre\", \"prend\", \"décider\", \"choisir\", \"obtenir\"]\n",
    "\n",
    "verbs_parameters = make_translation_dataframe(verbs_fr, verbs_en)\n",
    "display(verbs_parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t(fr,en)</th>\n",
       "      <th>livre</th>\n",
       "      <th>histoire</th>\n",
       "      <th>image</th>\n",
       "      <th>base</th>\n",
       "      <th>pièce</th>\n",
       "      <th>chambre</th>\n",
       "      <th>salle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>0.875130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookbook</td>\n",
       "      <td>0.321081</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>story</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>history</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.151446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671820</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>picture</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.308828</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.759858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>basis</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.549682</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>database</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.466398</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>basic</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439953</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>room</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.252917</td>\n",
       "      <td>0.037236</td>\n",
       "      <td>0.423155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t(fr,en)     livre  histoire     image      base     pièce   chambre  \\\n",
       "0       book  0.875130  0.000000  0.000000  0.000000  0.000010  0.000010   \n",
       "1   cookbook  0.321081  0.000010  0.000010  0.000010  0.000010  0.000010   \n",
       "2      story  0.000000  0.523640  0.000000  0.000010  0.000000  0.000010   \n",
       "3    history  0.000010  0.151446  0.000000  0.000000  0.000000  0.000010   \n",
       "4      image  0.000010  0.000000  0.671820  0.000010  0.000010  0.000010   \n",
       "5    picture  0.000000  0.000010  0.308828  0.000010  0.000000  0.000010   \n",
       "6       base  0.000010  0.000002  0.000010  0.759858  0.000000  0.000010   \n",
       "7      basis  0.000010  0.000010  0.000010  0.549682  0.000010  0.000010   \n",
       "8   database  0.000010  0.000010  0.000010  0.466398  0.000010  0.000010   \n",
       "9      basic  0.000010  0.000000  0.000000  0.439953  0.000010  0.000010   \n",
       "10      room  0.000010  0.000000  0.000000  0.000010  0.252917  0.037236   \n",
       "\n",
       "       salle  \n",
       "0   0.000000  \n",
       "1   0.000010  \n",
       "2   0.000010  \n",
       "3   0.000010  \n",
       "4   0.000010  \n",
       "5   0.000000  \n",
       "6   0.000010  \n",
       "7   0.000010  \n",
       "8   0.000010  \n",
       "9   0.000000  \n",
       "10  0.423155  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nouns_fr = [\"livre\", \"histoire\", \"image\", \"base\", \"pièce\", \"chambre\", \"salle\"]\n",
    "nouns_en = [\"book\", \"cookbook\", \"story\", \"history\", \"image\", \"picture\", \"base\", \"basis\", \"database\", \"basic\", \"room\"]\n",
    "\n",
    "verbs_parameters = make_translation_dataframe(nouns_fr, nouns_en)\n",
    "display(verbs_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Les alignements entre mots de phrases\n",
    " \n",
    "Les alignements de mots nous indiquent les mots d'une paires de phrases qui sont associés entre eux. Les alignements qui sont retournés indiquent les positions des mots dans les phrases. Nous présentons un exemple dans cette section.\n",
    "\n",
    "Note: il faut que le modèle utilisé ait été entraîné sur les paires de phrases pour avoir les alignements de ces phrases. Autrement dit, si vous montez le modèle avec Pickle, les phrases du corpus ne seront pas alignées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase source: ['Most', 'of', 'the', 'animals', 'are', 'in', 'the', 'oceans.']\n",
      "Phrase cible: ['La', 'plupart', 'des', 'animaux', 'se', 'trouvent', 'dans', 'les', 'océans.']\n",
      "\n",
      "Alignement par position: 0-0 1-0 2-1 3-3 4-7 5-7 6-5 7-4 8-7\n",
      "\n",
      "Les mots correspondants à ces positions: \n",
      "\t La <-- Most\n",
      "\t plupart <-- Most\n",
      "\t des <-- of\n",
      "\t animaux <-- animals\n",
      "\t se <-- oceans.\n",
      "\t trouvent <-- oceans.\n",
      "\t dans <-- in\n",
      "\t les <-- are\n",
      "\t océans. <-- oceans.\n"
     ]
    }
   ],
   "source": [
    "sentence_alignment =  aligned_text[10]\n",
    "print(\"Phrase source:\", sentence_alignment.mots)\n",
    "print(\"Phrase cible:\", sentence_alignment.words)\n",
    "print(\"\\nAlignement par position:\", sentence_alignment.alignment)\n",
    "\n",
    "print(\"\\nLes mots correspondants à ces positions: \")\n",
    "word_alignments = sorted(sentence_alignment.alignment, key = lambda x: x[0])\n",
    "for idx, idy in word_alignments:\n",
    "    x = sentence_alignment.words[idx]\n",
    "    y = sentence_alignment.mots[idy]\n",
    "    print(\"\\t\", x, \"<--\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_alignment(alignment):\n",
    "    source = sentence_alignment.words\n",
    "    target = sentence_alignment.mots\n",
    "    zeros = np.zeros((len(source), len(target)))  # nrows, ncolumns\n",
    "    df = pd.DataFrame(np.zeros((len(target), len(source))), index=target, columns=source) \n",
    "    for idx, idy in sentence_alignment.alignment:\n",
    "        df.iloc[idy, idx] = 1\n",
    "    plt.figure(figsize = (12,8))\n",
    "    ax = sns.heatmap(df, cbar=False, cmap=\"winter\")\n",
    "    ax.xaxis.tick_top()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_alignment(aligned_text[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Alignement de type phrased-based à partir des alignements de mots individuels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phrase source: The average depth is about two miles.\n",
      "Phrase cible: La profondeur moyenne est environ 3,2 km.\n",
      "Alignement de mots individuels: 0-0 1-2 2-1 3-3 4-4 5-6 6-6 \n",
      "\n",
      "((0, 1), (0, 1), 'The', 'La')\n",
      "((0, 3), (0, 3), 'The average depth', 'La profondeur moyenne')\n",
      "((0, 4), (0, 4), 'The average depth is', 'La profondeur moyenne est')\n",
      "((0, 5), (0, 5), 'The average depth is about', 'La profondeur moyenne est environ')\n",
      "((0, 5), (0, 6), 'The average depth is about', 'La profondeur moyenne est environ 3,2')\n",
      "((0, 7), (0, 7), 'The average depth is about two miles.', 'La profondeur moyenne est environ 3,2 km.')\n",
      "((1, 2), (2, 3), 'average', 'moyenne')\n",
      "((1, 3), (1, 3), 'average depth', 'profondeur moyenne')\n",
      "((1, 4), (1, 4), 'average depth is', 'profondeur moyenne est')\n",
      "((1, 5), (1, 5), 'average depth is about', 'profondeur moyenne est environ')\n",
      "((1, 5), (1, 6), 'average depth is about', 'profondeur moyenne est environ 3,2')\n",
      "((1, 7), (1, 7), 'average depth is about two miles.', 'profondeur moyenne est environ 3,2 km.')\n",
      "((2, 3), (1, 2), 'depth', 'profondeur')\n",
      "((3, 4), (3, 4), 'is', 'est')\n",
      "((3, 5), (3, 5), 'is about', 'est environ')\n",
      "((3, 5), (3, 6), 'is about', 'est environ 3,2')\n",
      "((3, 7), (3, 7), 'is about two miles.', 'est environ 3,2 km.')\n",
      "((4, 5), (4, 5), 'about', 'environ')\n",
      "((4, 5), (4, 6), 'about', 'environ 3,2')\n",
      "((4, 7), (4, 7), 'about two miles.', 'environ 3,2 km.')\n",
      "((5, 7), (5, 7), 'two miles.', '3,2 km.')\n",
      "((5, 7), (6, 7), 'two miles.', 'km.')\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.phrase_based import phrase_extraction\n",
    "\n",
    "def extract_phrase_alignments(aligned_sentences):\n",
    "    src_text = \" \".join(aligned_sentences.mots)\n",
    "    trg_text = \" \".join(aligned_sentences.words)\n",
    "    alignment = aligned_sentences.alignment\n",
    "    phrase_alignments = phrase_extraction(src_text, trg_text, alignment)\n",
    "    print(\"\\nPhrase source:\", src_text)\n",
    "    print(\"Phrase cible:\", trg_text)\n",
    "    print(\"Alignement de mots individuels:\", alignment, \"\\n\")\n",
    "    for phrase_alignment in sorted(phrase_alignments):\n",
    "        print(phrase_alignment)\n",
    "        \n",
    "extract_phrase_alignments(aligned_text[7])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Évaluation de la traduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Les deux traductions à évaluer:\n",
      "['Mary', 'no', 'slap', 'the', 'witch', 'green']\n",
      "['Mary', 'did', 'not', 'give', 'a', 'smack', 'to', 'a', 'green', 'witch']\n",
      "\n",
      "Les phrases de référence: \n",
      "['Mary', 'did', 'not', 'slap', 'the', 'green', 'witch']\n",
      "['Mary', 'did', 'not', 'smack', 'the', 'green', 'witch']\n",
      "['Mary', 'did', 'not', 'hit', 'a', 'green', 'sorceress']\n",
      "\n",
      "Évaluation BLEU de cand1: 0.3455747170954952\n",
      "Évaluation BLEU de cand2: 0.557773351022717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\program files\\python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "cand1 = \"Mary no slap the witch green\".split()\n",
    "cand2 = \"Mary did not give a smack to a green witch\".split()\n",
    "\n",
    "ref1 = \"Mary did not slap the green witch\".split()\n",
    "ref2 = \"Mary did not smack the green witch\".split()\n",
    "ref3 = \"Mary did not hit a green sorceress\".split()\n",
    "refs = [ref1, ref2, ref3]\n",
    "\n",
    "print(\"\\nLes deux traductions à évaluer:\\n{}\\n{}\".format(cand1, cand2))\n",
    "print(\"\\nLes phrases de référence: \")\n",
    "for ref in refs:\n",
    "    print(ref)\n",
    "\n",
    "ngram_weights=(0.5, 0.5, 0.0, 0.0)  # On utilise seulement les unigrammes et bigrammes pour l'évaluation\n",
    "score1 = sentence_bleu(refs, cand1, weights=ngram_weights)\n",
    "print(\"\\nÉvaluation BLEU de cand1:\", score1)\n",
    "\n",
    "score2 = sentence_bleu(refs, cand2, weights=ngram_weights)\n",
    "print(\"Évaluation BLEU de cand2:\", score2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
